{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SzymonNowakowski/Machine-Learning-2024/blob/master/Lab11-autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 11 - Autoencoders\n",
        "### Author: Szymon Nowakowski"
      ],
      "metadata": {
        "id": "xl_-W_aXqjJ2"
      },
      "id": "xl_-W_aXqjJ2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Introduction\n",
        "--------------\n",
        "\n",
        "Autoencoders can be thought of as nonlinear extensions of PCA. In this class, we’ll train an autoencoder on the MNIST dataset and compare its encoded representation to the PCA space we constructed earlier (remember our very first class?). This comparison will help us see whether the autoencoder captures the structure of the data more effectively.\n",
        "\n",
        "Next, we’ll put the trained autoencoder to practical use. It is great in anomaly detection (identification of outliers) and image denoising.\n",
        "\n",
        "You’ll also notice that throughout this class, we’re treating the images in a class-diagnostic, unsupervised manner—focusing on the structure of the data itself, rather than on labels."
      ],
      "metadata": {
        "id": "fMvw34S08ZvN"
      },
      "id": "fMvw34S08ZvN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deterministic output\n",
        "--------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "VnC1WjOL5-Pd"
      },
      "id": "VnC1WjOL5-Pd"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "SEED = 0\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n"
      ],
      "metadata": {
        "id": "0wwOGe0j5nMk"
      },
      "id": "0wwOGe0j5nMk",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading MNIST Dataset\n",
        "----------------------------------"
      ],
      "metadata": {
        "id": "jBj9rZpumQ2a"
      },
      "id": "jBj9rZpumQ2a"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from matplotlib import pyplot\n",
        "\n",
        "transform = torchvision.transforms.ToTensor() #Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "\n",
        "     # note - we are NOT normalizing pixels, as we want to keep 0-1 range\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data',\n",
        "                                      train=True,\n",
        "                                      download=True,\n",
        "                                      transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=2048,\n",
        "                                          shuffle=True)   #we do shuffle it to give more randomizations to training epochs\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data',\n",
        "                                     train=False,\n",
        "                                     download=True,\n",
        "                                     transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=1,\n",
        "                                         shuffle=False)\n"
      ],
      "metadata": {
        "id": "K_b3NgK0mT9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b34f05a-b7c5-4010-fe08-58a333523df1"
      },
      "id": "K_b3NgK0mT9C",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 494kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.39MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.95MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Sizes\n",
        "-------------------\n",
        "\n",
        "Recall:\n",
        "- Batched labels are of order one. The first (and only) index is a sample index within a batch. **The labels, however, are of no direct interest to us during this class**.\n",
        "- Image batches have order 4. The first index is a sample index within a batch, but a second index has size 1 and thus it is always 0.\n",
        "  - This index represents a Channel number inserted here by `ToTensor()` transformation, always 0.\n",
        "  - It should be retained because we want to use convolutional layers, which explicitly require this order. For RGB images we have 3 channels, for B&W images we have only one channel.\n"
      ],
      "metadata": {
        "id": "KpN_zrBRmd6D"
      },
      "id": "KpN_zrBRmd6D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder and Decoder Networks\n",
        "-----------------\n",
        "\n",
        "Autoencoder is an Encoder followed by a Decoder, as in this diagram: ![Autoencoder](https://github.com/SzymonNowakowski/Machine-Learning-2024/raw/master/autoencoder_diagram.png\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "YAihBeAxndOm"
      },
      "id": "YAihBeAxndOm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "XOkTnHzLojq4"
      },
      "id": "XOkTnHzLojq4"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EncoderMLP(nn.Module):\n",
        "    def __init__(self, bottleneck_dimensionality):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),                           # 1x28x28 -> 784\n",
        "            nn.Linear(784, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, bottleneck_dimensionality)  # -> bottleneck\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n"
      ],
      "metadata": {
        "id": "JwvCLWJvp065"
      },
      "id": "JwvCLWJvp065",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "I4jGHOdaonuz"
      },
      "id": "I4jGHOdaonuz"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DecoderMLP(nn.Module):\n",
        "    def __init__(self, bottleneck_dimensionality):\n",
        "        super().__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(bottleneck_dimensionality, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 784),\n",
        "            nn.Sigmoid(),             # Output in [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.decoder(x)\n",
        "        return x.view(-1, 1, 28, 28)  # Reshape to image. -1 means \"infer the proper dimensionality automatically\"\n"
      ],
      "metadata": {
        "id": "3TpKt8o0o1YZ"
      },
      "id": "3TpKt8o0o1YZ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder\n"
      ],
      "metadata": {
        "id": "KRGa98OBoqCF"
      },
      "id": "KRGa98OBoqCF"
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, bottleneck_dimensionality):\n",
        "        super().__init__()\n",
        "        self.encoder = EncoderMLP(bottleneck_dimensionality)\n",
        "        self.decoder = DecoderMLP(bottleneck_dimensionality)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2c62Xk_xot2i"
      },
      "id": "2c62Xk_xot2i",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop\n",
        "----------------------\n",
        "\n",
        "Beware: Training takes around 10 minutes on a GPU, and closer to an hour on a CPU. I had the joy of discovering that firsthand when Colab temporarily revoked my GPU access."
      ],
      "metadata": {
        "id": "NFBpFy6FqLhL"
      },
      "id": "NFBpFy6FqLhL"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Working on {device}\")\n",
        "\n",
        "net = Autoencoder(bottleneck_dimensionality=2).to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "EPOCHS = 128\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # === Train ===\n",
        "    net.train()\n",
        "    epoch_loss_sum = 0.0\n",
        "    epoch_sample_count = 0\n",
        "\n",
        "    for batch_inputs, _ in trainloader:\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed = net(batch_inputs)\n",
        "\n",
        "        loss = F.mse_loss(reconstructed, batch_inputs, reduction='mean')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = batch_inputs.size(0)\n",
        "        epoch_loss_sum += loss.item() * batch_size\n",
        "        epoch_sample_count += batch_size\n",
        "\n",
        "    avg_train_loss = epoch_loss_sum / epoch_sample_count\n",
        "    train_loss_history.append(avg_train_loss)\n",
        "\n",
        "    # === Evaluate on test set ===\n",
        "    net.eval()\n",
        "    test_loss_sum = 0.0\n",
        "    test_sample_count = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, _ in testloader:\n",
        "            batch_inputs = batch_inputs.to(device)\n",
        "            reconstructed = net(batch_inputs)\n",
        "            loss = F.mse_loss(reconstructed, batch_inputs, reduction='mean')\n",
        "\n",
        "            batch_size = batch_inputs.size(0)\n",
        "            test_loss_sum += loss.item() * batch_size\n",
        "            test_sample_count += batch_size\n",
        "\n",
        "    avg_test_loss = test_loss_sum / test_sample_count\n",
        "    test_loss_history.append(avg_test_loss)\n",
        "\n",
        "    if epoch % 16 == 0:\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss (averaged over the epoch): {avg_train_loss:.6f} | Test Loss (after the epoch): {avg_test_loss:.6f}\")\n",
        "\n",
        "# End timing\n",
        "end_time = time.time()\n",
        "print(f\"Elapsed time: {end_time - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "uyEA3Qk3qMj6",
        "outputId": "872bae5f-cd9e-401b-c012-358ec399a5c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uyEA3Qk3qMj6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on cpu\n",
            "Epoch 000 | Train Loss (averaged over the epoch): 0.126929 | Test Loss (after the epoch): 0.073962\n",
            "Epoch 016 | Train Loss (averaged over the epoch): 0.048716 | Test Loss (after the epoch): 0.048246\n",
            "Epoch 032 | Train Loss (averaged over the epoch): 0.043901 | Test Loss (after the epoch): 0.043801\n",
            "Epoch 048 | Train Loss (averaged over the epoch): 0.041402 | Test Loss (after the epoch): 0.041567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_history, label=\"Train loss\", color='blue')\n",
        "plt.plot(test_loss_history, label=\"Test loss\", color='orange')\n",
        "plt.title(\"Autoencoder Loss per Epoch (Avg per Sample)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Average Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "FPrz9Lxn0aLH"
      },
      "id": "FPrz9Lxn0aLH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visual Testing\n",
        "----------------------"
      ],
      "metadata": {
        "id": "E2IB8sviqsir"
      },
      "id": "E2IB8sviqsir"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Number of examples to show\n",
        "N = 20\n",
        "\n",
        "net.eval()\n",
        "fig, axs = plt.subplots(2, N, figsize=(2 * N, 4))\n",
        "\n",
        "test_iter = iter(testloader)\n",
        "for i in range(N):\n",
        "    img, _ = next(test_iter)\n",
        "    img = img.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        recon = net(img)\n",
        "\n",
        "    axs[0, i].imshow(img[0, 0].cpu().numpy(), cmap=\"gray\")\n",
        "    axs[0, i].axis(\"off\")\n",
        "    axs[1, i].imshow(recon[0, 0].cpu().numpy(), cmap=\"gray\")\n",
        "    axs[1, i].axis(\"off\")\n",
        "\n",
        "axs[0, 0].set_title(\"Original\")\n",
        "axs[1, 0].set_title(\"Reconstructed\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ubj7gcEjrs50"
      },
      "id": "ubj7gcEjrs50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latent Space\n",
        "----------------------\n",
        "\n",
        "It is instructive to plot the bottleneck (for the test set) in a 2D plot. As a comparison, we will plot the PCA of the test set to the side."
      ],
      "metadata": {
        "id": "PmJMqeN0QoFB"
      },
      "id": "PmJMqeN0QoFB"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# === Collect latent codes and raw data ===\n",
        "net.eval()\n",
        "all_latents = []\n",
        "all_labels = []\n",
        "raw_images = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        latents = net.encoder(inputs)\n",
        "\n",
        "        all_latents.append(latents.cpu())\n",
        "        all_labels.append(labels)\n",
        "        raw_images.append(inputs.cpu().view(inputs.size(0), -1))  # Flatten: (B, 784)\n",
        "\n",
        "all_latents = torch.cat(all_latents).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "raw_images = torch.cat(raw_images).numpy()\n",
        "\n",
        "# === PCA ===\n",
        "pca = PCA(n_components=2)\n",
        "raw_images_2d = pca.fit_transform(raw_images)\n",
        "\n",
        "# === Plot side-by-side with proper colorbar ===\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Bottleneck\n",
        "sc1 = axes[0].scatter(all_latents[:, 0], all_latents[:, 1], c=all_labels, cmap=\"tab10\", s=10, alpha=0.7)\n",
        "axes[0].set_title(\"2D Bottleneck (Autoencoder)\")\n",
        "axes[0].set_xlabel(\"Latent dim 1\")\n",
        "axes[0].set_ylabel(\"Latent dim 2\")\n",
        "axes[0].grid(True)\n",
        "\n",
        "# PCA\n",
        "sc2 = axes[1].scatter(raw_images_2d[:, 0], raw_images_2d[:, 1], c=all_labels, cmap=\"tab10\", s=10, alpha=0.7)\n",
        "axes[1].set_title(\"PCA of Original Images (Flattened)\")\n",
        "axes[1].set_xlabel(\"PC1\")\n",
        "axes[1].set_ylabel(\"PC2\")\n",
        "axes[1].grid(True)\n",
        "\n",
        "# Shared colorbar – place to the right of both subplots\n",
        "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
        "fig.colorbar(sc2, cax=cbar_ax, ticks=range(10), label='Digit Label')\n",
        "\n",
        "plt.subplots_adjust(right=0.9)  # make room for colorbar\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qN3DCG45QrW0"
      },
      "id": "qN3DCG45QrW0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16 Dimensional Bottleneck\n",
        "\n",
        "To experience a little bit more expressive network, let us now train another network, with a 16D bottleneck:"
      ],
      "metadata": {
        "id": "JOpt2Y5qW75z"
      },
      "id": "JOpt2Y5qW75z"
    },
    {
      "cell_type": "code",
      "source": [
        "#### TRAINING\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Working on {device}\")\n",
        "\n",
        "net_16 = Autoencoder(bottleneck_dimensionality=16).to(device)\n",
        "optimizer = torch.optim.Adam(net_16.parameters(), lr=0.001)\n",
        "\n",
        "EPOCHS = 128\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # === Train ===\n",
        "    net_16.train()\n",
        "    epoch_loss_sum = 0.0\n",
        "    epoch_sample_count = 0\n",
        "\n",
        "    for batch_inputs, _ in trainloader:\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed = net_16(batch_inputs)\n",
        "\n",
        "        loss = F.mse_loss(reconstructed, batch_inputs, reduction='mean')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = batch_inputs.size(0)\n",
        "        epoch_loss_sum += loss.item() * batch_size\n",
        "        epoch_sample_count += batch_size\n",
        "\n",
        "    avg_train_loss = epoch_loss_sum / epoch_sample_count\n",
        "    train_loss_history.append(avg_train_loss)\n",
        "\n",
        "    # === Evaluate on test set ===\n",
        "    net_16.eval()\n",
        "    test_loss_sum = 0.0\n",
        "    test_sample_count = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, _ in testloader:\n",
        "            batch_inputs = batch_inputs.to(device)\n",
        "            reconstructed = net_16(batch_inputs)\n",
        "            loss = F.mse_loss(reconstructed, batch_inputs, reduction='mean')\n",
        "\n",
        "            batch_size = batch_inputs.size(0)\n",
        "            test_loss_sum += loss.item() * batch_size\n",
        "            test_sample_count += batch_size\n",
        "\n",
        "    avg_test_loss = test_loss_sum / test_sample_count\n",
        "    test_loss_history.append(avg_test_loss)\n",
        "\n",
        "    if epoch % 16 == 0:\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss (averaged over the epoch): {avg_train_loss:.6f} | Test Loss (after the epoch): {avg_test_loss:.6f}\")\n",
        "\n",
        "# End timing\n",
        "end_time = time.time()\n",
        "print(f\"Elapsed time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "#### VISUALISING LEARNING PROGRESS\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_history, label=\"Train loss\", color='blue')\n",
        "plt.plot(test_loss_history, label=\"Test loss\", color='orange')\n",
        "plt.title(\"Autoencoder Loss per Epoch (Avg per Sample)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Average Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#### SOME EXAMPLES\n",
        "\n",
        "N = 20 # Number of examples to show\n",
        "\n",
        "net_16.eval()\n",
        "fig, axs = plt.subplots(2, N, figsize=(2 * N, 4))\n",
        "\n",
        "test_iter = iter(testloader)\n",
        "for i in range(N):\n",
        "    img, _ = next(test_iter)\n",
        "    img = img.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        recon = net_16(img)\n",
        "\n",
        "    axs[0, i].imshow(img[0, 0].cpu().numpy(), cmap=\"gray\")\n",
        "    axs[0, i].axis(\"off\")\n",
        "    axs[1, i].imshow(recon[0, 0].cpu().numpy(), cmap=\"gray\")\n",
        "    axs[1, i].axis(\"off\")\n",
        "\n",
        "axs[0, 0].set_title(\"Original\")\n",
        "axs[1, 0].set_title(\"Reconstructed\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#### AND FINALY THE 16D BOTTLENECK PLOTTED (ONLY ITS 2 PRINCIPAL COMPONENTS GET PLOTTED)\n",
        "\n",
        "net.eval()\n",
        "net_16.eval()\n",
        "\n",
        "def get_latents(net, dataloader):\n",
        "    all_latents, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            latents = net.encoder(inputs)\n",
        "            all_latents.append(latents.cpu())\n",
        "            all_labels.append(labels)\n",
        "    return torch.cat(all_latents).numpy(), torch.cat(all_labels).numpy()\n",
        "\n",
        "# Get latent spaces\n",
        "latents_2d, labels = get_latents(net, testloader)\n",
        "latents_16d, _ = get_latents(net_16, testloader)\n",
        "\n",
        "# PCA: 16D to 2D\n",
        "pca = PCA(n_components=2)\n",
        "latents_16d_pca = pca.fit_transform(latents_16d)\n",
        "\n",
        "# Plot side-by-side\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "scatter1 = axes[0].scatter(latents_2d[:, 0], latents_2d[:, 1], c=labels, cmap='tab10', s=10, alpha=0.7)\n",
        "axes[0].set_title(\"True 2D Bottleneck (net)\")\n",
        "axes[0].set_xlabel(\"Dim 1\")\n",
        "axes[0].set_ylabel(\"Dim 2\")\n",
        "axes[0].grid(True)\n",
        "\n",
        "scatter2 = axes[1].scatter(latents_16d_pca[:, 0], latents_16d_pca[:, 1], c=labels, cmap='tab10', s=10, alpha=0.7)\n",
        "axes[1].set_title(\"PCA of 16D Bottleneck (net_16)\")\n",
        "axes[1].set_xlabel(\"PC 1\")\n",
        "axes[1].set_ylabel(\"PC 2\")\n",
        "axes[1].grid(True)\n",
        "\n",
        "# Shared colorbar\n",
        "fig.colorbar(scatter1, ax=axes.ravel().tolist(), ticks=range(10), label='Digit Label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2GP3lTJuXhLP"
      },
      "id": "2GP3lTJuXhLP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}