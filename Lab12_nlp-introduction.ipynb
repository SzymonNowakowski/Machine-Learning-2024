{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SzymonNowakowski/Machine-Learning-2024/blob/master/Lab12_nlp-introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12 - Natural Language Processing - Introduction\n",
        "\n",
        "### Author: Szymon Nowakowski\n"
      ],
      "metadata": {
        "id": "xl_-W_aXqjJ2"
      },
      "id": "xl_-W_aXqjJ2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "---------------\n",
        "In this class, we take our first steps into Natural Language Processing (NLP). We'll begin by averaging word embeddings to form sentence-level representations—a simple but effective baseline. **Attention** generalizes this idea by learning which words matter more in context, assigning dynamic weights instead of treating each word equally. In this sense, **attention can be thought of as a learned, weighted average**.\n",
        "\n",
        "This is our gateway into more advanced techniques. In the next class, we’ll study **self-attention**, the backbone of modern architectures like the Transformer. And if time permits, we may even explore the **full Transformer** model in our final class.\n",
        "\n",
        "I would like to express my gratitude to my colleague Przemysław Olbratowski for this elegant way of introducing attention, which I find both intuitive and pedagogically effective.\n"
      ],
      "metadata": {
        "id": "kzosqJ1czsY9"
      },
      "id": "kzosqJ1czsY9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yelp Reviews Polarity Dataset  \n",
        "--------------\n",
        "\n",
        "This dataset contains **over 560k full-text reviews** from Yelp, labeled for **binary sentiment**:  \n",
        "- **positive** (5-star reviews)  \n",
        "- **negative** (1-star reviews)  \n",
        "\n",
        "We will not use the full dataset, because it cannot be handled by Colab RAM.\n",
        "\n",
        "Each example is a **real user-generated review**, typically 2–5 sentences long, capturing clear and direct sentiment in natural language.  \n",
        "There are no ambiguous or neutral labels, making this dataset ideal for training and evaluating **binary sentiment classifiers**.\n",
        "\n",
        "The dataset was curated and released as part of the **FastText** and **Text Classification Benchmarks** by researchers at Facebook AI. It is widely used for benchmarking sentiment models in both academia and industry.\n"
      ],
      "metadata": {
        "id": "G7rPtPD1zvCV"
      },
      "id": "G7rPtPD1zvCV"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVUhR__7NByz",
        "outputId": "335bf460-f322-44e3-87a5-87a2cbc81dee"
      },
      "id": "yVUhR__7NByz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import collections\n",
        "import re                             # Regular Expressions: for text searching and cleaning\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Load Yelp Polarity dataset from Hugging Face (one-time use)\n",
        "raw = load_dataset(\"yelp_polarity\")\n",
        "\n",
        "N_TRAIN = 100_000\n",
        "N_TEST = 20_000   # VAL + TEST sets\n",
        "\n",
        "train_raw = raw[\"train\"].shuffle(seed=42).select(range(N_TRAIN))\n",
        "test_raw  = raw[\"test\"].shuffle(seed=42).select(range(N_TEST))\n",
        "\n",
        "\n",
        "# Extract plain Python lists for text and labels\n",
        "def to_lists(dataset):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for example in dataset:\n",
        "        texts.append(example[\"text\"])\n",
        "        labels.append(example[\"label\"])\n",
        "    return texts, labels\n",
        "\n",
        "train_texts, train_labels = to_lists(train_raw)\n",
        "test_texts, test_labels   = to_lists(test_raw)\n",
        "\n",
        "# Split test set into val/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    test_texts, test_labels, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Show class counts\n",
        "def print_distribution(name, labels):\n",
        "    c = collections.Counter(labels)\n",
        "    total = sum(c.values())\n",
        "    print(f\"\\n{name} distribution:\")\n",
        "    for label in sorted(c.keys()):\n",
        "        print(f\"  {label}: {c[label]} ({c[label]/total:.2%})\")\n",
        "\n",
        "print_distribution(\"Train\", train_labels)\n",
        "print_distribution(\"Validation\", val_labels)\n",
        "print_distribution(\"Test\", test_labels)\n"
      ],
      "metadata": {
        "id": "E8GmG8SAzsE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "a15c60f7ea014664a40b76972082cb5e",
            "b6e0cd517cd7492cadcde80a07f0ee66",
            "f2fc7eed7e8a4eee88030250a1a19eaa",
            "35aea88cc1fa4511b21a18f0c1e32a7f",
            "0e7a1ac2525744b1aee7a84cfdc27a3e",
            "dafe28f80743488ab1ef7e7d91852ef4",
            "83a3c6280f224d21b1b95c429a6c8ca3",
            "592710f5443e4b22a7e4912fb838bf3c",
            "2fb548aee07b4ec9a8369b24f87df7c5",
            "629e125325c647b48fd378916fd7b8af",
            "79746c6fdfb04aed9fe0f118efef096d",
            "64e50e2bddd24b81aab8963b89884d1e",
            "4eaf29b36be24ab180faf67aa4bf8048",
            "af9af3ae6caf4cf5981e6660059c6fed",
            "7c9f9edd95a94ab29529c22e9630cecb",
            "a0780befeec84ac7a88e37c4cb7dd46f",
            "eb8f328c1a264963b7c906b0cc3042f7",
            "ff9c3aa47a6e492d9d22dafe3759bfbe",
            "b4616d37172a47ae841dbb3440522638",
            "3a5e6e6f6c5e4999a7d04e2506046998",
            "0b43ec689db741a496f6e8c86abcd9f9",
            "35903715bd524a40b4951a449bd44787",
            "4b7b0111d1c645899f0d38c030006a29",
            "3d3d7d448e0649bcbfca4b2cbcbd4302",
            "f471763cb2e3427292545ac06aaf9dec",
            "fe66cf067afd4e3db04bff14620f318a",
            "44111adfa2d04377b50b05a517b47621",
            "e4afff3bd3214443a0b8fcc195252eae",
            "f7946c9975eb4ae29b4933b11fd57d78",
            "c7cfd50e724b4ae6baaa3ae296af455e",
            "7232d41e00414721bc8b688a34e5c2fc",
            "88407057360040acb8c88471425029d8",
            "ba3e13590be744969dd38455293bf13d",
            "6b5813d50db140eca5933ceecd709769",
            "f14edbf698144e41a1bd52597b25915e",
            "bc38233ca0dd4273a6366330f9ea5f83",
            "8ad4efa708634361acd08780507bb091",
            "fe564f6f79054c41b7690e87e82e4c91",
            "29e38eadd12643c79ab8a37fa1958f79",
            "f0606ea899b245abba2db2ba39d342de",
            "4adc9a1f105340cfa018f50fe4a3ecfe",
            "1a9c4e44dca14a6696e9582f885106fd",
            "9a5fdfc578ae463098d85ded4b887359",
            "e304f062a6744ff3952d9b2384a2d30b",
            "a7aabeb3193541b69f2aa5bd583ee184",
            "7cba04d750694bd2997d35a0d7761c06",
            "e5534950790c4453bdeda05411b16c47",
            "651422a7d7ef4ca2a0cb74bc6e31627f",
            "36cb95eb588d45fda56cc68c1c8ef73d",
            "376ced9cfcb444fab373baef65a8ba8f",
            "08f482e274fb4adaba85e8add0f5551c",
            "7ee76a8d86fc460db1cb3e98912f0c4d",
            "2edad2d1205b41d598df05493571ac86",
            "6f4eed357e6e44ac9e0d7b889bfca35f",
            "01df3cc8c94f4bd48768b10106ab3ea7"
          ]
        },
        "outputId": "50967c7b-c851-4083-efd5-60b3d4a5ca37"
      },
      "id": "E8GmG8SAzsE6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.93k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a15c60f7ea014664a40b76972082cb5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64e50e2bddd24b81aab8963b89884d1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b7b0111d1c645899f0d38c030006a29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/560000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b5813d50db140eca5933ceecd709769"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/38000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7aabeb3193541b69f2aa5bd583ee184"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train distribution:\n",
            "  0: 50209 (50.21%)\n",
            "  1: 49791 (49.79%)\n",
            "\n",
            "Validation distribution:\n",
            "  0: 5038 (50.38%)\n",
            "  1: 4962 (49.62%)\n",
            "\n",
            "Test distribution:\n",
            "  0: 4973 (49.73%)\n",
            "  1: 5027 (50.27%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some examples"
      ],
      "metadata": {
        "id": "oH3nWRZnNAxB"
      },
      "id": "oH3nWRZnNAxB"
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {0: \"negative\", 1: \"positive\"}\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"[{label_map[train_labels[i]]}] {train_texts[i]}\\n\")"
      ],
      "metadata": {
        "id": "2swC8sM0ND49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca482a3-31cc-467a-e6df-8b6c0728134d"
      },
      "id": "2swC8sM0ND49",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[positive] Decent size, decent selection, decent staff.\\n\\nI guess that can wholly sum this place up, it's decent.  As with many other stores that are like this, the product rotates depending on what doesn't sale well at other stores.  Can always snag a deal here.  I was able to pick up a pretty sweet Puma jacket for $10, can't beat that, right?\\n\\nThat being said, there are those times that you may not find anything as well.  So really don't get your hopes up if you are looking for a specific item.\n",
            "\n",
            "[negative] I have definitely experienced better! Let's see, so I first brought my car here to get the brakes done and they did a pretty good job, although, every time I'm in reverse, my brakes do make a squeaking noise. Not sure what's up with that. Anyway, needless to say, they did a pretty good job on my brakes. \\n\\nSince my last brake job, they have switched managers and the service has kinda gone down hill. I brought my car in to have the control arm bushings done. They quoted me a little under $500 to have this done, which wasn't really that much cheaper than the dealer. The dealer was about $50 more and would have given me a loaner vehicle to use. \\n\\nAnyway, I brought my car in to have them work on it. I dropped it off at 12:00pm, which was my scheduled appointment time. At 2:30pm I received a call from the manager stating that they ordered the wrong part and couldn't do the work on the car today. He told me I could either pick it up or just leave it there. I'm not sure why it took 2 1/2 hours to figure out that you ordered the wrong part...but I didn't have 2 days to spend on having my vehicle repaired. I mean, my whole day was pretty much wasted. \\n\\nI decided to pick my car up and call around to see if there was another repair shop to do the work I requested. I wound up finding Kelly's Automotive Repair in Fountain Hills to do the work for $357 including parts, labor, shop supplies, etc. Needless to say, because Just Brakes was incompetent in ordering the wrong part...and taking 2 1/2 hours to figure it out, they lost my business. Silver lining is that I saved over $100 by them doing that.\\n\\nI'll probably bring my car back for them to look at why my brakes squeak when I back up, since they were the last ones who did my brakes. Other than that, I don't really trust them anymore.\n",
            "\n",
            "[negative] Food is mediocre at best. I came in one day and ordered the lo mein and they use spaghetti pasta to pass as lo mein noodles.\n",
            "\n",
            "[positive] Best casino in the PHX area.\n",
            "\n",
            "[positive] This place is a must try! Truly a fan of Skinny Fats!\\n\\nThe first time I went was around lunchtime, so I tried the Buff Chix- so yummy! Love the buffalo sauce! \\n\\nThe next time I went was for breakfast, so I decided to try 3 Happy Chicks. Again- so yummy! This is now my go to item all the time! Especially since they serve breakfast all day!\\n\\nI would love to try everything on the menu! But every time I go, I always seem to order the 3 Happy Chicks!  It's a simple breakfast- just made perfectly! \\n\\nThe location is a smaller place, which is always packed, but I think that this is just part of the fun and experience!\\n \\nThe staff is amazing... full of fun, and awesome-ness, and just always in a great mood!\n",
            "\n",
            "[positive] This is just for the food. I wish I could have seen a band here, but was in town for business and just didn't have time. I flew in from KC late Monday night (for my time zone) and missed dinner with my coworkers, so I decided to head out on my own. I was staying at Mandalay Bay, so I didn't have far to go to House of Blues. It's right in that complex.\\n\\nI asked to sit at the bar. That's usually what I do if i am eating alone. You get seated right away, your server is never far away and the service is usually superb. I was not disappointed.\\n\\nI asked the bartender for a light, savory gin drink. I can't remember what he called it, but it hit the spot. Then I asked what was good on the menu. Initially he said, \\\"\"Everything\\\"\". I said BS to that. Then he asked what I wanted - I said something light, it's late for me. So, he recommended the shrimp tacos.\\n\\nThe food came out pretty quickly. The shrimp tacos were really good. Lots of shrimp, nicely seasoned with a little kick. I asked for hot sauce, but all they had was Tabasco. That surprised me. Didn't this chain start in New Orleans? However, they had some sauce that really highlighted the flavor, so kudos.\\n\\nI was out in less than an hour. Nice dinner. I'd go back - next time for a concert, hopefully.\n",
            "\n",
            "[positive] Best fried rice I've tried. My girlfriend ordered the shrimp fried rice and added jalapenos and XO sauce and it was delicious! Its not on the menu but you can ask for it. The beef chow fun was good too but a little plain.\n",
            "\n",
            "[negative] One of the low end Japanese express style of restaurants in the university area. The rice is horrible, the plates are over priced ($2-$3 dollars more than other places),  and the serve is mediocre at best. \\n\\nGiven the option, I'd steer clear of this place and go other \\\"\"quality\\\"\" restaurants in the area. But i'd say try this place out if you enjoy drowning your plates in shrimp sauce; Its all going to taste the same anyways.\n",
            "\n",
            "[negative] The only benefit to this place was that it was a good deal. That being said, it was dirty, DIRTY- like we had to get a new room because we couldn't stand the shower-scum shower, dust coming out of fans and stains on pillows that came from questionable sources. It is off the strip, so you have to take the bus to drop you off, which can lead to a 45 minute wait. The inside needs some serious updating to match the other hotels, looks as if it is stuck in the 80's. Tube TV's in the rooms, no fan in the bathrooms, keurig machines in rooms that don't work..This place needs some serious work. Will NOT be staying here again.\n",
            "\n",
            "[negative] I have never written a review, but the food at Havana Cafe was so underwhelming (and not in the least bit good) that I feel compelled to share. \\nI ordered the Pollo Ajillo which, in reality, was a pile of salt with a side of chicken and rice. I opted for Arroz con Gandules instead of white rice as it has been years since I have had this tasty Puerto Rican side. The whole thing was almost inedible... I came home and actually brushed my teeth immediately, it was so bad!  My husband had the Pollo Cubano, which was equally underwhelming and nothing that we could not make at home ourselves.  The restaurant gets an extra star for the wonderful Cafe Cubano and the extremely attentive wait staff .  I had high hopes for this place but the next time I have a craving for Cuban food, I will be heading to Sabor Cubano.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer\n",
        "-------------------\n",
        "\n",
        "To feed text into a neural network, we need to represent words in a \"neural-network-ish\" way — that is, as numbers. The standard approach is to use a tokenizer, often from a pretrained model. However, since we plan to experiment with our own attention modules later on, **we’ll avoid using any pretrained tokenizer**.\n",
        "\n",
        "Instead, we’ll go with a simple, word-based tokenization. As part of this, we’ll clean the text by removing any non-standard HTML tags, digits, extra whitespace, and punctuation. We’ll also convert all words to lowercase to ensure consistency."
      ],
      "metadata": {
        "id": "T07SvDTYV6nO"
      },
      "id": "T07SvDTYV6nO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Special Tokens: `<PAD>` and `<UNK>`\n",
        "\n",
        "In our text preprocessing pipeline, we convert each word to a number using a vocabulary. Two special tokens help us handle padding and unknown words.\n"
      ],
      "metadata": {
        "id": "IyT2bcscZu4P"
      },
      "id": "IyT2bcscZu4P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### `<PAD>` — Padding Token\n",
        "\n",
        "- Represents empty slots when we need all input sequences to be the same length.\n",
        "- Assigned index `0`.\n",
        "- Used so that batches of sentences can be processed together by the model.\n",
        "\n",
        "*For example:*\n",
        "\n",
        "Original: `[17, 5, 23]`  \n",
        "Padded:   `[17, 5, 23, 0, 0]` (for a fixed length of 5)"
      ],
      "metadata": {
        "id": "Ha9i37gvaBUn"
      },
      "id": "Ha9i37gvaBUn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### `<UNK>` — Unknown Token\n",
        "\n",
        "- Represents any word that is **not in the vocabulary**.\n",
        "- Assigned index `1`.\n",
        "- Occurs when:\n",
        "  1. A word was **too rare in the training data** (appeared only once and was excluded from the vocabulary).\n",
        "  2. A word appears **only in validation or test data**.\n",
        "\n",
        "> In our setup, we **excluded all words that appear only once** in the training set.  \n",
        "> So even in the training data, some tokens are replaced with `<UNK>`.  \n",
        "> These are called **rare unknowns** — they help the model learn how to handle unusual or unfamiliar words.\n",
        "\n",
        "\n",
        "By including `<UNK>` during training, we teach the model how to deal with unseen or rare words at test time — which is **crucial for generalization**.\n"
      ],
      "metadata": {
        "id": "3Rymjwd6ZsoK"
      },
      "id": "3Rymjwd6ZsoK"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<[^>]+>', ' ', text)\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text.split()\n",
        "\n",
        "def build_vocab(token_lists, min_freq=2):\n",
        "    counter = collections.Counter(token for tokens in token_lists for token in tokens)\n",
        "    vocab = {\n",
        "        token: idx + 2  # reserve 0: <PAD>, 1: <UNK>\n",
        "        for idx, (token, count) in enumerate(counter.items())\n",
        "        if count >= min_freq\n",
        "    }\n",
        "    vocab['<PAD>'] = 0\n",
        "    vocab['<UNK>'] = 1\n",
        "    return vocab\n",
        "\n",
        "def tokens_to_ids(tokens, vocab):\n",
        "    return [vocab.get(tok, vocab['<UNK>']) for tok in tokens]   #for unknown tokens return vocab['<UNK>'] (which is == 1)\n",
        "\n",
        "def pad(seq, max_len=128, pad_value=0):\n",
        "    return seq + [pad_value] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len]\n",
        "\n",
        "def process_texts(texts, vocab, max_len=128):\n",
        "    return [pad(tokens_to_ids(tokenize(text), vocab), max_len) for text in texts]\n",
        "\n",
        "\n",
        "# Tokenize training set and build vocab\n",
        "train_tokens = [tokenize(t) for t in train_texts]\n",
        "vocab = build_vocab(train_tokens)\n",
        "\n",
        "# Process splits into padded input_ids\n",
        "train_ids = process_texts(train_texts, vocab, MAX_LEN)\n",
        "val_ids   = process_texts(val_texts, vocab, MAX_LEN)\n",
        "test_ids  = process_texts(test_texts, vocab, MAX_LEN)\n",
        "\n",
        "# Print 5 real examples: raw text, tokenized, and input IDs\n",
        "shown = 0\n",
        "for i in range(len(train_texts)):\n",
        "    if 1 in train_ids[i][:5]:  # 1 is <UNK>\n",
        "        print(f\"Original:   {train_texts[i]}\")\n",
        "        print(f\"Tokenized:  {train_tokens[i]}\")\n",
        "        print(f\"Input IDs:  {train_ids[i]}\\n\")\n",
        "        shown += 1\n",
        "        if shown >= 5:\n",
        "            break\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bNJLBhifYFhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d116a400-72c9-4d58-cb9e-a41932fef407"
      },
      "id": "bNJLBhifYFhO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   I've been to Benihannas several times in a California and Arizona. I must say that there isn't any consistency with this place. The one here in chandler is not very good. I think they are surviving off of the reputation not customer service. First the girl working as the hostess needs to learn how to smile and actually act like she likes her job. Word of advice for her. If you can't smile, be cordial, have a personality then quit and find another line of work but obviously interacting with the public is not your calling. \\n\\nVery long wait to eat.... The servers are slow and you have to wait forever just to get drinks and refills...\\n\\nI think for $100 I can spend it elsewhere and get better service and food...\n",
            "Tokenized:  ['i', 've', 'been', 'to', 'benihannas', 'several', 'times', 'in', 'a', 'california', 'and', 'arizona', 'i', 'must', 'say', 'that', 'there', 'isn', 't', 'any', 'consistency', 'with', 'this', 'place', 'the', 'one', 'here', 'in', 'chandler', 'is', 'not', 'very', 'good', 'i', 'think', 'they', 'are', 'surviving', 'off', 'of', 'the', 'reputation', 'not', 'customer', 'service', 'first', 'the', 'girl', 'working', 'as', 'the', 'hostess', 'needs', 'to', 'learn', 'how', 'to', 'smile', 'and', 'actually', 'act', 'like', 'she', 'likes', 'her', 'job', 'word', 'of', 'advice', 'for', 'her', 'if', 'you', 'can', 't', 'smile', 'be', 'cordial', 'have', 'a', 'personality', 'then', 'quit', 'and', 'find', 'another', 'line', 'of', 'work', 'but', 'obviously', 'interacting', 'with', 'the', 'public', 'is', 'not', 'your', 'calling', 'n', 'nvery', 'long', 'wait', 'to', 'eat', 'the', 'servers', 'are', 'slow', 'and', 'you', 'have', 'to', 'wait', 'forever', 'just', 'to', 'get', 'drinks', 'and', 'refills', 'n', 'ni', 'think', 'for', 'i', 'can', 'spend', 'it', 'elsewhere', 'and', 'get', 'better', 'service', 'and', 'food']\n",
            "Input IDs:  [41, 358, 455, 44, 1, 1015, 58, 95, 38, 990, 86, 1016, 41, 233, 104, 9, 56, 1017, 32, 846, 1018, 19, 13, 14, 25, 223, 40, 95, 1019, 201, 61, 522, 89, 41, 270, 87, 23, 1020, 140, 237, 25, 1021, 61, 506, 110, 80, 25, 1022, 1023, 18, 25, 1024, 416, 44, 1025, 936, 44, 864, 86, 464, 1026, 24, 621, 1027, 611, 90, 1028, 237, 1029, 50, 611, 70, 59, 10, 32, 864, 431, 1030, 74, 38, 1031, 323, 1032, 86, 62, 178, 653, 237, 138, 166, 620, 1033, 19, 25, 1034, 201, 61, 68, 1035, 6, 1036, 676, 414, 44, 584, 25, 1037, 23, 1038, 86, 59, 74, 44, 414, 1039, 159, 44, 67, 526, 86, 1040, 6, 7, 270, 50, 41, 10, 169]\n",
            "\n",
            "Original:   A terible place. The speakers were blown out the camera was off focus. After complaining they said they fixed it but nothing changed.\n",
            "Tokenized:  ['a', 'terible', 'place', 'the', 'speakers', 'were', 'blown', 'out', 'the', 'camera', 'was', 'off', 'focus', 'after', 'complaining', 'they', 'said', 'they', 'fixed', 'it', 'but', 'nothing', 'changed']\n",
            "Input IDs:  [38, 1, 14, 25, 2842, 214, 2829, 165, 25, 2843, 42, 140, 2844, 645, 2845, 87, 55, 87, 2846, 16, 166, 472, 2663, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Original:   There are two wingharts. One in market square. One on Carson street in the Southside. \\n\\nPros: staff is super nice at both locations. Pizza oven in market square is different so if you are going for pizza go to market square location. It's amazing and you can taste the freshness. The burgers are big and from what my husband says, are delish. At both locations. Pierogies yum.  \\n\\nCons: in market square it's tiny and narrow and in the summer can be very hot with the pizza oven.\n",
            "Tokenized:  ['there', 'are', 'two', 'wingharts', 'one', 'in', 'market', 'square', 'one', 'on', 'carson', 'street', 'in', 'the', 'southside', 'n', 'npros', 'staff', 'is', 'super', 'nice', 'at', 'both', 'locations', 'pizza', 'oven', 'in', 'market', 'square', 'is', 'different', 'so', 'if', 'you', 'are', 'going', 'for', 'pizza', 'go', 'to', 'market', 'square', 'location', 'it', 's', 'amazing', 'and', 'you', 'can', 'taste', 'the', 'freshness', 'the', 'burgers', 'are', 'big', 'and', 'from', 'what', 'my', 'husband', 'says', 'are', 'delish', 'at', 'both', 'locations', 'pierogies', 'yum', 'n', 'ncons', 'in', 'market', 'square', 'it', 's', 'tiny', 'and', 'narrow', 'and', 'in', 'the', 'summer', 'can', 'be', 'very', 'hot', 'with', 'the', 'pizza', 'oven']\n",
            "Input IDs:  [56, 23, 768, 1, 223, 95, 3523, 3524, 223, 29, 3525, 728, 95, 25, 3526, 6, 2639, 5, 201, 1402, 352, 35, 1235, 3527, 701, 1907, 95, 3523, 3524, 201, 688, 64, 70, 59, 23, 389, 50, 701, 256, 44, 3523, 3524, 267, 16, 17, 273, 86, 59, 10, 390, 25, 1156, 25, 804, 23, 1258, 86, 146, 30, 82, 469, 922, 23, 2916, 35, 1235, 3527, 3528, 1601, 6, 2643, 95, 3523, 3524, 16, 17, 2549, 86, 3338, 86, 95, 25, 2297, 10, 431, 522, 336, 19, 25, 701, 1907, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Original:   I go to einsteins petoodically because its close to home. I always pay with my debit card. On my statement in May it showed 25 charges for the same amount, on the same day, with same reference number. I showed these charges to the district manager. She basically said she would not reimburse me. My bank...US bank said because it was more than 60 days..they couldnt help me...Im out over $200.....I would recommend that anyone wanting bagels..should not buy here..\n",
            "Tokenized:  ['i', 'go', 'to', 'einsteins', 'petoodically', 'because', 'its', 'close', 'to', 'home', 'i', 'always', 'pay', 'with', 'my', 'debit', 'card', 'on', 'my', 'statement', 'in', 'may', 'it', 'showed', 'charges', 'for', 'the', 'same', 'amount', 'on', 'the', 'same', 'day', 'with', 'same', 'reference', 'number', 'i', 'showed', 'these', 'charges', 'to', 'the', 'district', 'manager', 'she', 'basically', 'said', 'she', 'would', 'not', 'reimburse', 'me', 'my', 'bank', 'us', 'bank', 'said', 'because', 'it', 'was', 'more', 'than', 'days', 'they', 'couldnt', 'help', 'me', 'im', 'out', 'over', 'i', 'would', 'recommend', 'that', 'anyone', 'wanting', 'bagels', 'should', 'not', 'buy', 'here']\n",
            "Input IDs:  [41, 256, 44, 4272, 1, 193, 364, 603, 44, 463, 41, 36, 642, 19, 82, 4274, 1339, 29, 82, 4275, 95, 60, 16, 2308, 4276, 50, 25, 391, 2235, 29, 25, 391, 174, 19, 391, 3683, 844, 41, 2308, 554, 4276, 44, 25, 4277, 147, 621, 986, 55, 621, 131, 61, 4278, 120, 82, 3008, 623, 3008, 55, 193, 16, 42, 130, 127, 168, 87, 4279, 847, 120, 1011, 165, 203, 41, 131, 655, 9, 1396, 2011, 4280, 624, 61, 891, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Original:   The service was curtuous and knowledgeable... The food was quite ordinary, not the level of what I expected from the critics I read on that restaurant.  The decor is rather dark and sad, the tables were too close to a point that you cannot hear the people sitting at your own table.\\nA disappointing experience\n",
            "Tokenized:  ['the', 'service', 'was', 'curtuous', 'and', 'knowledgeable', 'the', 'food', 'was', 'quite', 'ordinary', 'not', 'the', 'level', 'of', 'what', 'i', 'expected', 'from', 'the', 'critics', 'i', 'read', 'on', 'that', 'restaurant', 'the', 'decor', 'is', 'rather', 'dark', 'and', 'sad', 'the', 'tables', 'were', 'too', 'close', 'to', 'a', 'point', 'that', 'you', 'cannot', 'hear', 'the', 'people', 'sitting', 'at', 'your', 'own', 'table', 'na', 'disappointing', 'experience']\n",
            "Input IDs:  [25, 110, 42, 1, 86, 3449, 25, 219, 42, 1058, 3094, 61, 25, 2137, 237, 30, 41, 982, 146, 25, 5596, 41, 2849, 29, 9, 474, 25, 2197, 201, 617, 3118, 86, 1173, 25, 694, 214, 368, 603, 44, 38, 894, 9, 59, 2689, 1928, 25, 601, 1739, 35, 68, 293, 609, 1430, 2207, 272, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notice!\n",
        "\n",
        "Notice that the `<UNK>` token (coded as 1) is visible in the rows above. Also, there is an abundance of `<PAD>` tokens (coded as 0)."
      ],
      "metadata": {
        "id": "cSDc_W9S89ZU"
      },
      "id": "cSDc_W9S89ZU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data Loaders\n",
        "--------------------\n",
        "\n",
        "We must transform the pandas dataframe to the dataset - it will, among other things, separate input data and labels and then wrap it in a dataloder."
      ],
      "metadata": {
        "id": "XDLaOuwegNXu"
      },
      "id": "XDLaOuwegNXu"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SoiJPpApJe9L"
      },
      "id": "SoiJPpApJe9L"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Convert all to tensors\n",
        "def to_loader(input_ids, labels, batch_size=1024, shuffle=False):\n",
        "    x_tensor = torch.tensor(input_ids, dtype=torch.long)\n",
        "    y_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "    return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_tensor, y_tensor), batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "train_loader = to_loader(train_ids, train_labels, BATCH_SIZE, shuffle=True)\n",
        "val_loader   = to_loader(val_ids, val_labels, BATCH_SIZE)\n",
        "test_loader  = to_loader(test_ids, test_labels, BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "432ev7Jxg9Fw"
      },
      "id": "432ev7Jxg9Fw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop as We Already Got to Know It Well\n",
        "----------------"
      ],
      "metadata": {
        "id": "bOD1hweknD7z"
      },
      "id": "bOD1hweknD7z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Loop Function"
      ],
      "metadata": {
        "id": "7kZDRRGS-yMI"
      },
      "id": "7kZDRRGS-yMI"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Working on {device}\")\n",
        "\n",
        "def train_model(net, train_loader, val_loader, epochs=1000, lr=0.001, log_every=10):\n",
        "    print(f\"Working on {device}\")\n",
        "    net = net.to(device)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "        train_loss_sum = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch_inputs, batch_labels in train_loader:\n",
        "            batch_inputs = batch_inputs.to(device)\n",
        "            batch_labels = batch_labels.to(device).float()  # shape: (batch_size)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = net(batch_inputs)  # logits shape: (batch_size, 1)\n",
        "            loss = criterion(logits, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_sum += loss.item() * batch_inputs.size(0)\n",
        "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "            train_correct += (preds == batch_labels).sum().item()\n",
        "            train_total += batch_inputs.size(0)\n",
        "\n",
        "        avg_train_loss = train_loss_sum / train_total\n",
        "        train_acc = train_correct / train_total\n",
        "        train_loss_history.append(avg_train_loss)\n",
        "        train_acc_history.append(train_acc)\n",
        "\n",
        "        # === Validation ===\n",
        "        net.eval()\n",
        "        val_loss_sum = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_inputs, batch_labels in val_loader:\n",
        "                batch_inputs = batch_inputs.to(device)\n",
        "                batch_labels = batch_labels.to(device).float()\n",
        "\n",
        "                logits = net(batch_inputs)\n",
        "                loss = criterion(logits, batch_labels)\n",
        "\n",
        "                val_loss_sum += loss.item() * batch_inputs.size(0)\n",
        "                preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "                val_correct += (preds == batch_labels).sum().item()\n",
        "                val_total += batch_inputs.size(0)\n",
        "\n",
        "        avg_val_loss = val_loss_sum / val_total\n",
        "        val_acc = val_correct / val_total\n",
        "        val_loss_history.append(avg_val_loss)\n",
        "        val_acc_history.append(val_acc)\n",
        "\n",
        "        if epoch % log_every == 0:\n",
        "            print(f\"Epoch {epoch:03d} | \"\n",
        "                  f\"Train Loss: {avg_train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "                  f\"Val Loss: {avg_val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Elapsed time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    return train_loss_history, val_loss_history, train_acc_history, val_acc_history"
      ],
      "metadata": {
        "id": "HCA6aXtlnH6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bedaee2-80c1-4134-9a23-28e4a436dfc8"
      },
      "id": "HCA6aXtlnH6J",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Function"
      ],
      "metadata": {
        "id": "-P8_EMUj-tnp"
      },
      "id": "-P8_EMUj-tnp"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_curves(train_loss, val_loss, train_acc, val_acc):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Plot Loss\n",
        "    axs[0].plot(train_loss, label=\"Train Loss\", color='blue')\n",
        "    axs[0].plot(val_loss, label=\"Val Loss\", color='orange')\n",
        "    axs[0].set_title(\"Loss per Epoch\")\n",
        "    axs[0].set_xlabel(\"Epoch\")\n",
        "    axs[0].set_ylabel(\"Average Loss\")\n",
        "    axs[0].grid(True)\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Plot Accuracy\n",
        "    axs[1].plot(train_acc, label=\"Train Accuracy\", color='green')\n",
        "    axs[1].plot(val_acc, label=\"Val Accuracy\", color='red')\n",
        "    axs[1].set_title(\"Accuracy per Epoch\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Accuracy\")\n",
        "    axs[1].grid(True)\n",
        "    axs[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mDuVP9J6zl0T"
      },
      "id": "mDuVP9J6zl0T",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple 1 Feature Aproach\n",
        "------------------\n",
        "\n",
        "Before we proceed with a multi-feature network, let's try to go simpler, for a moment. Let's consider a single feature."
      ],
      "metadata": {
        "id": "_GUYSKp3HlRK"
      },
      "id": "_GUYSKp3HlRK"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cnt = 1\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Net_1(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, feature_cnt)\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                        #batch, words\n",
        "        features = self.embedding(index)             #batch, words, features\n",
        "        features = features.mean(-2)                 #batch, features\n",
        "        classifications = self.classifier(features)  #batch, 1\n",
        "        logits = classifications.squeeze(-1)         #batch\n",
        "        return logits\n",
        "\n",
        "net_1 = Net_1()\n",
        "\n",
        "# Execute training\n",
        "train_loss, val_loss, train_acc, val_acc = train_model(net_1, train_loader, val_loader, epochs = 100)\n",
        "plot_training_curves(train_loss, val_loss, train_acc, val_acc)"
      ],
      "metadata": {
        "id": "mNwmWLEuHrOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2acf257-b045-4be4-c757-077c996d5690"
      },
      "id": "mNwmWLEuHrOD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on cuda\n",
            "Epoch 000 | Train Loss: 0.7007, Acc: 0.4979 | Val Loss: 0.6985, Acc: 0.4962\n",
            "Epoch 010 | Train Loss: 0.6517, Acc: 0.6052 | Val Loss: 0.6466, Acc: 0.6161\n",
            "Epoch 020 | Train Loss: 0.5326, Acc: 0.7709 | Val Loss: 0.5270, Acc: 0.7757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Polarity\n",
        "\n",
        "Since our embeddings have only 1 feature (`feature_cnt = 1`), each word is embedded to a scalar. We can interpret this scalar as a kind of sentiment polarity, especially since our model is trained for sentiment classification."
      ],
      "metadata": {
        "id": "mlg7DIdoXA_Y"
      },
      "id": "mlg7DIdoXA_Y"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the embedding weights as a NumPy array\n",
        "embedding_weights = net_1.embedding.weight.detach().cpu().numpy().squeeze()  # shape: (vocab_len,)\n",
        "\n",
        "# Reverse vocab dictionary to map indices back to words\n",
        "id2token = {idx: token for token, idx in vocab.items()}\n",
        "\n",
        "# Skip <PAD> and <UNK> tokens (indices 0 and 1)\n",
        "valid_indices = np.array([idx for idx in range(2, len(embedding_weights)) if idx in id2token])\n",
        "valid_embeddings = embedding_weights[valid_indices]\n",
        "\n",
        "# Sort and select indices\n",
        "sorted_pos = np.argsort(-valid_embeddings)\n",
        "sorted_neg = np.argsort(valid_embeddings)\n",
        "sorted_neutral = np.argsort(np.abs(valid_embeddings))\n",
        "\n",
        "top_pos_indices = valid_indices[sorted_pos[:20]]\n",
        "top_neg_indices = valid_indices[sorted_neg[:20]]\n",
        "top_neutral_indices = valid_indices[sorted_neutral[:20]]\n",
        "\n",
        "# Print words and corresponding embedding values\n",
        "def print_words_with_embeddings(indices, title):\n",
        "    print(f\"\\n{title}\")\n",
        "    for idx in indices:\n",
        "        word = id2token[int(idx)]\n",
        "        value = embedding_weights[int(idx)]\n",
        "        print(f\"{word:15} -> {value:.4f}\")\n",
        "\n",
        "print_words_with_embeddings(top_pos_indices, \"Top 20 most positive words:\")\n",
        "print_words_with_embeddings(top_neg_indices, \"Top 20 most negative words:\")\n",
        "print_words_with_embeddings(top_neutral_indices, \"Top 20 most neutral words:\")\n"
      ],
      "metadata": {
        "id": "zPijTrZEXvM4"
      },
      "id": "zPijTrZEXvM4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classificator\n",
        "\n",
        "It is interesting to see how the polar sentiment gets translated into the two  class values. Let's see:"
      ],
      "metadata": {
        "id": "ayZtmbdcvPyP"
      },
      "id": "ayZtmbdcvPyP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract weights and bias from the classifier layer\n",
        "classifier_weight = net_1.classifier.weight.detach().cpu().numpy()\n",
        "classifier_bias = net_1.classifier.bias.detach().cpu().numpy()\n",
        "\n",
        "print(\"Classifier weights (shape: {}):\".format(classifier_weight.shape))\n",
        "print(classifier_weight)\n",
        "\n",
        "print(\"\\nClassifier bias (shape: {}):\".format(classifier_bias.shape))\n",
        "print(classifier_bias)\n",
        "\n",
        "print(\"Recall our coding: \")\n",
        "print(label_map)\n"
      ],
      "metadata": {
        "id": "0Ra3BaKGv7ib"
      },
      "id": "0Ra3BaKGv7ib",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hand-picked test sentences\n",
        "texts = [\n",
        "    \"I love this\",\n",
        "    \"I like this\",\n",
        "    \"I do not like this\",\n",
        "    \"I don't like this\",\n",
        "    \"This is terrible\",\n",
        "    \"Thank you so much!\",\n",
        "    \"I hate this\",\n",
        "    \"I don't hate this\",\n",
        "    \"This sucks!\"\n",
        "]\n",
        "\n",
        "# Convert texts to input_ids using your tokenizer\n",
        "input_ids = process_texts(texts, vocab)\n",
        "input_tensor = torch.tensor(input_ids).to(next(net_1.parameters()).device)\n",
        "\n",
        "# Predict with trained model\n",
        "net_1.eval()\n",
        "with torch.no_grad():\n",
        "    logits = net_1(input_tensor).squeeze()\n",
        "    probs = torch.sigmoid(logits)\n",
        "\n",
        "# Print results\n",
        "for text, prob in zip(texts, probs):\n",
        "    print(f\"{text:30} -> predicted probability of POSITIVE: {prob.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "00X0GbtFELx7"
      },
      "id": "00X0GbtFELx7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Artificial (Concatenated) Sentences\n",
        "-----------------\n",
        "\n",
        "It will make the dataset diffinitely more demanding and also more suited for attention that we intend to add later.\n",
        "\n",
        "Every original sentence appears as the first part of a mixed sentence, so every label is retained. Then, the second random sentence is concatenated. As an effect, we generate as many augmented samples as there are originals. So number of samples and the label distribution is retained.\n",
        "\n",
        "The classifier must learn to focus on the first sentence and ignore the distractor that follows. This provides a clear, controlled task that makes attention valuable:\n",
        " - With attention: the model can learn to give weight to the first part.\n",
        " - Without it: a mean-pool model may be diluted by the second sentence."
      ],
      "metadata": {
        "id": "wj10SuUbZDmM"
      },
      "id": "wj10SuUbZDmM"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "\n",
        "MAX_LEN = 256  # changing max len to accomodate longer sequences, also, longer sequences are harder for the mean network\n",
        "\n",
        "def pair_every_sentence_with_random(texts, labels, seed=42):\n",
        "    \"\"\"\n",
        "    For each sentence, append a randomly selected second sentence.\n",
        "    The label of the first is preserved.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    n = len(texts)\n",
        "\n",
        "    augmented_texts = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for i in range(n):\n",
        "        first = texts[i]\n",
        "        label = labels[i]\n",
        "\n",
        "        second = texts[random.randint(0, n - 1)]\n",
        "\n",
        "        combined = second + \" \" + first # we prepend the sentence with a random one, now\n",
        "\n",
        "        augmented_texts.append(combined)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "    return texts + augmented_texts, labels + augmented_labels\n",
        "\n",
        "\n",
        "train_texts, train_labels = pair_every_sentence_with_random(train_texts, train_labels)\n",
        "val_texts, val_labels     = pair_every_sentence_with_random(val_texts,   val_labels)\n",
        "test_texts, test_labels   = pair_every_sentence_with_random(test_texts,  test_labels)\n",
        "\n",
        "# Reprocess splits into padded input_ids\n",
        "train_ids = process_texts(train_texts, vocab, MAX_LEN)\n",
        "val_ids   = process_texts(val_texts, vocab, MAX_LEN)\n",
        "test_ids  = process_texts(test_texts, vocab, MAX_LEN)\n",
        "\n",
        "# Recalculate data loaders\n",
        "train_loader = to_loader(train_ids, train_labels, BATCH_SIZE, shuffle=True)\n",
        "val_loader   = to_loader(val_ids, val_labels, BATCH_SIZE)\n",
        "test_loader  = to_loader(test_ids, test_labels, BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "p_XV_kiyZOEf"
      },
      "id": "p_XV_kiyZOEf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Features, Now\n",
        "---------------"
      ],
      "metadata": {
        "id": "Gn__dzYW2PWA"
      },
      "id": "Gn__dzYW2PWA"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cnt = 16\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Net_F(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, feature_cnt)\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                        #batch, words\n",
        "        features = self.embedding(index)             #batch, words, features\n",
        "        features = features.mean(-2)                 #batch, features\n",
        "        classifications = self.classifier(features)  #batch, 1\n",
        "        logits = classifications.squeeze(-1)         #batch\n",
        "        return logits\n",
        "\n",
        "net_f=Net_F()\n",
        "train_loss, val_loss, train_acc, val_acc = train_model(net_f, train_loader, val_loader, epochs=50)\n",
        "plot_training_curves(train_loss, val_loss, train_acc, val_acc)"
      ],
      "metadata": {
        "id": "fSsb18Pf2hZP"
      },
      "id": "fSsb18Pf2hZP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Towards Attention!\n",
        "---------------------------\n"
      ],
      "metadata": {
        "id": "cnwL4ci4aRMK"
      },
      "id": "cnwL4ci4aRMK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Entry Point\n",
        "\n",
        "The entry point is our model with averaged multiple features:"
      ],
      "metadata": {
        "id": "ZeX-Tnlra-pY"
      },
      "id": "ZeX-Tnlra-pY"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cnt = 16\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Net_F(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, feature_cnt)\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                        #SIZE: batch, words\n",
        "        features = self.embedding(index)             #SIZE: batch, words, features\n",
        "\n",
        "        ### This is where AVERAGING takes place\n",
        "        features = features.mean(-2)                 #SIZE: batch, features\n",
        "\n",
        "\n",
        "        classifications = self.classifier(features)  #SIZE: batch, 1\n",
        "        logits = classifications.squeeze(-1)         #SIZE: batch\n",
        "        return logits"
      ],
      "metadata": {
        "id": "diAmuIhIbHOQ"
      },
      "id": "diAmuIhIbHOQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Less Explicit Averaging"
      ],
      "metadata": {
        "id": "H-g5Q7KxbWzG"
      },
      "id": "H-g5Q7KxbWzG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below is equivalent to taking the `mean()` over words:"
      ],
      "metadata": {
        "id": "KLDhT9JCd9gh"
      },
      "id": "KLDhT9JCd9gh"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cnt = 16\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Net_Towards_Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, feature_cnt)\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                            #SIZE: batch, words\n",
        "        features = self.embedding(index)                 #SIZE: batch, words, features\n",
        "\n",
        "        ### This is where WHEIGHTED AVERAGING with EQUAL WEIGHTS takes place\n",
        "        batch = features.size(0)          # get the batch dimension\n",
        "        words = features.size(1)          # get the words dimension\n",
        "        weights = torch.ones((batch, 1, words)) / words   # create EQUAL WEIGHT tensor summing to 1.0 ( words x (1/words) )\n",
        "                                                         #SIZE: batch, 1, words\n",
        "        features = weights @ features                    #SIZE: batch, 1, features\n",
        "\n",
        "\n",
        "        classifications = self.classifier(features)      #SIZE: batch, 1, 1\n",
        "        logits = classifications.squeeze(-1).squeeze(-1) #SIZE: batch\n",
        "        return logits"
      ],
      "metadata": {
        "id": "epoXI3SZbcHg"
      },
      "id": "epoXI3SZbcHg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let us refactor this, taking the weighted average part into a separate `Attention` module:"
      ],
      "metadata": {
        "id": "OFcB29hteVru"
      },
      "id": "OFcB29hteVru"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cnt = 16\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, features):                         #SIZE: batch, words, features\n",
        "        batch = features.size(0)          # get the batch dimension\n",
        "        words = features.size(1)          # get the words dimension\n",
        "        weights = torch.ones((batch, 1, words)) / words   # create EQUAL WEIGHT tensor summing to 1.0 ( words x (1/words) )\n",
        "                                                         #SIZE: batch, 1, words\n",
        "        features = weights @ features                    #SIZE: batch, 1, features\n",
        "        return features\n",
        "\n",
        "class Net_Towards_Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, feature_cnt)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                            #SIZE: batch, words\n",
        "        features = self.embedding(index)                 #SIZE: batch, words, features\n",
        "\n",
        "        ### This is where WHEIGHTED AVERAGING with EQUAL WEIGHTS takes place\n",
        "        features = self.attention(features)              #SIZE: batch, 1, features\n",
        "\n",
        "        classifications = self.classifier(features)      #SIZE: batch, 1, 1\n",
        "        logits = classifications.squeeze(-1).squeeze(-1) #SIZE: batch\n",
        "        return logits"
      ],
      "metadata": {
        "id": "8FzeUuJ-ehns"
      },
      "id": "8FzeUuJ-ehns",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All that we did up until that point was to rewrite taking the `mean()` into a separate `Attention` which calculates the weighted averager with equal weights over weights."
      ],
      "metadata": {
        "id": "fKuofPqsfWxe"
      },
      "id": "fKuofPqsfWxe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing the Notion of Energy\n",
        "\n",
        "Another useful concept is that of the energy. The energy equal to 0 uniformly for all words translates (with the use of `softmax`) into the equal weights, so the below version is still equivalent to what we already had (but, arguably, it looks much more complex):"
      ],
      "metadata": {
        "id": "3cFkehdKf1vE"
      },
      "id": "3cFkehdKf1vE"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "feature_cnt = 16\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, features):                        #SIZE: batch, words, features\n",
        "        batch = features.size(0)          # get the batch dimension\n",
        "        words = features.size(1)          # get the words dimension\n",
        "        energies = torch.zeros((batch, 1, words))       #SIZE: batch, 1, words\n",
        "        weights = F.softmax(energies, -1)               #SIZE: batch, 1, words\n",
        "        features = weights @ features                   #SIZE: batch, 1, features\n",
        "        return features\n",
        "\n",
        "class Net_Towards_Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, feature_cnt)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                            #SIZE: batch, words\n",
        "        features = self.embedding(index)                 #SIZE: batch, words, features\n",
        "\n",
        "        ### This is where WHEIGHTED AVERAGING with EQUAL WEIGHTS takes place\n",
        "        features = self.attention(features)              #SIZE: batch, 1, features\n",
        "\n",
        "        classifications = self.classifier(features)      #SIZE: batch, 1, 1\n",
        "        logits = classifications.squeeze(-1).squeeze(-1) #SIZE: batch\n",
        "        return logits"
      ],
      "metadata": {
        "id": "IVkMyyYjgN6p"
      },
      "id": "IVkMyyYjgN6p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Something New - Learned Energies"
      ],
      "metadata": {
        "id": "8Q4efFtch23v"
      },
      "id": "8Q4efFtch23v"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cnt = 16\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.energy = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, features):                        #SIZE: batch, words, features\n",
        "        batch = features.size(0)          # get the batch dimension\n",
        "        words = features.size(1)          # get the words dimension\n",
        "        energies = self.energy(features)                #SIZE: batch, words, 1\n",
        "        energies = energies.transpose(-2, -1)           #SIZE: batch, 1, words\n",
        "        weights = F.softmax(energies, -1)               #SIZE: batch, 1, words\n",
        "        features = weights @ features                   #SIZE: batch, 1, features\n",
        "        return features\n",
        "\n",
        "class Net_Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, feature_cnt)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                            #SIZE: batch, words\n",
        "        features = self.embedding(index)                 #SIZE: batch, words, features\n",
        "\n",
        "        ### This is where WHEIGHTED AVERAGING with LEARNED WEIGHTS takes place\n",
        "        features = self.attention(features)              #SIZE: batch, 1, features\n",
        "\n",
        "        classifications = self.classifier(features)      #SIZE: batch, 1, 1\n",
        "        logits = classifications.squeeze(-1).squeeze(-1) #SIZE: batch\n",
        "        return logits\n",
        "\n",
        "net_att = Net_Attention()\n",
        "\n",
        "# Execute training again\n",
        "train_loss, val_loss, train_acc, val_acc = train_model(net_att, train_loader, val_loader, epochs = 50)\n",
        "plot_training_curves(train_loss, val_loss, train_acc, val_acc)"
      ],
      "metadata": {
        "id": "8VLpkoPbh9LG"
      },
      "id": "8VLpkoPbh9LG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Encoding\n",
        "-----------------------"
      ],
      "metadata": {
        "id": "GnWwejPa68Fi"
      },
      "id": "GnWwejPa68Fi"
    },
    {
      "cell_type": "code",
      "source": [
        "pos_cnt = 16\n",
        "\n",
        "def sinusoid_positions(max_len = MAX_LEN, dim = pos_cnt):\n",
        "    pos = torch.arange(max_len, device=device).float().unsqueeze(1)\n",
        "    i   = torch.arange(dim, device=device).float().unsqueeze(0)\n",
        "    angle = pos / (10000 ** (2 * (i//2) / dim))\n",
        "    S = torch.zeros(max_len, dim, device=device)\n",
        "    S[:, 0::2] = torch.sin(angle[:, 0::2])\n",
        "    S[:, 1::2] = torch.cos(angle[:, 1::2])\n",
        "    return S          #  SIZE: words, features  (constant matrix throuoght all computations)\n",
        "\n"
      ],
      "metadata": {
        "id": "oz5NJuqA7qoT"
      },
      "id": "oz5NJuqA7qoT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Each position in the sequence gets a vector that is added (or concatenated) to the word embedding. The values in that vector are defined deterministically using sine and cosine waves of varying frequencies.\n",
        "\n",
        "For a given position $pos$ and dimension $i$ (where $i$ goes from $0$ to $d_{\\text{model}} - 1$):\n",
        "\n",
        "$$\n",
        "\\text{PE}_{pos, i} =\n",
        "\\begin{cases}\n",
        "\\sin\\left(\\frac{pos}{10000^{i / d_{\\text{model}}}}\\right), & \\text{if } i \\text{ is even} \\\\\n",
        "\\cos\\left(\\frac{pos}{10000^{(i - 1) / d_{\\text{model}}}}\\right), & \\text{if } i \\text{ is odd}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "**Why use sine and cosine?**\n",
        "\n",
        "- **Smoothness**: adjacent positions have similar encodings — helpful for capturing local context.\n",
        "- **Distance-preserving**: differences between position encodings reflect relative distances, which helps the attention mechanism.\n",
        "- **No training needed**: the encoding is deterministic, so it generalizes to sequences longer than those seen during training.\n"
      ],
      "metadata": {
        "id": "drCE7Wfv724t"
      },
      "id": "drCE7Wfv724t"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create sinusoidal matrix S\n",
        "S = sinusoid_positions()\n",
        "\n",
        "# Plot as heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(S, cmap=\"coolwarm\", cbar=True, xticklabels=2, yticklabels=4)\n",
        "plt.title(\"Heatmap of Sinusoidal Positional Encodings\")\n",
        "plt.xlabel(\"Embedding dimension\")\n",
        "plt.ylabel(\"Token position\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "R3PFWarM7O7C"
      },
      "id": "R3PFWarM7O7C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_cnt = 16          # word embeddings\n",
        "pos_cnt = 16            # pos embeddings\n",
        "feature_cnt = 16\n",
        "\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.energy = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, features):                        #SIZE: batch, words, features\n",
        "        batch = features.size(0)          # get the batch dimension\n",
        "        words = features.size(1)          # get the words dimension\n",
        "        energies = self.energy(features)                #SIZE: batch, words, 1\n",
        "        energies = energies.transpose(-2, -1)           #SIZE: batch, 1, words\n",
        "        weights = F.softmax(energies, -1)               #SIZE: batch, 1, words\n",
        "        features = weights @ features                   #SIZE: batch, 1, features\n",
        "        return features\n",
        "\n",
        "class Net_Attention_And_PE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, embed_cnt)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                            #SIZE: batch, words\n",
        "        features = self.embedding(index) + S             #SIZE: batch, words, features\n",
        "\n",
        "        ### This is where WHEIGHTED AVERAGING with LEARNED WEIGHTS takes place\n",
        "        features = self.attention(features)              #SIZE: batch, 1, features\n",
        "\n",
        "        classifications = self.classifier(features)      #SIZE: batch, 1, 1\n",
        "        logits = classifications.squeeze(-1).squeeze(-1) #SIZE: batch\n",
        "        return logits\n",
        "\n",
        "net_att_pe = Net_Attention_And_PE()\n",
        "\n",
        "# Execute training again\n",
        "train_loss, val_loss, train_acc, val_acc = train_model(net_att_pe, train_loader, val_loader, epochs = 20)\n",
        "plot_training_curves(train_loss, val_loss, train_acc, val_acc)"
      ],
      "metadata": {
        "id": "UyIkrhVH8FPD"
      },
      "id": "UyIkrhVH8FPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_cnt = 16          # word embeddings\n",
        "pos_cnt = 16             # pos embeddings\n",
        "feature_cnt = 16\n",
        "vocab_len = max(vocab.values()) + 1   # maximal value (index) of a token\n",
        "\n",
        "class Net_PE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_len, embed_cnt)\n",
        "        self.classifier = torch.nn.Linear(feature_cnt, 1)\n",
        "    def forward(self, index):                        #SIZE: batch, words\n",
        "        features = self.embedding(index) + S             #SIZE: batch, words, features\n",
        "\n",
        "        ### This is where AVERAGING takes place\n",
        "        features = features.mean(-2)                 #SIZE: batch, features\n",
        "\n",
        "        classifications = self.classifier(features)  #SIZE: batch, 1\n",
        "        logits = classifications.squeeze(-1)         #SIZE: batch\n",
        "        return logits\n",
        "\n",
        "net_pe = Net_PE()\n",
        "\n",
        "# Execute training again\n",
        "train_loss, val_loss, train_acc, val_acc = train_model(net_pe, train_loader, val_loader, epochs = 50)\n",
        "plot_training_curves(train_loss, val_loss, train_acc, val_acc)"
      ],
      "metadata": {
        "id": "qd-X2nqz9K96"
      },
      "id": "qd-X2nqz9K96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Weights Exploration\n",
        "\n",
        "Now that our attention-based model is trained, and is superior to non-attention model, let's take a closer look at what it's *actually attending to*. We'll manually construct artificial embeddings containing:\n",
        "\n",
        "- A strongly positive word (`phenomenal`)\n",
        "- A strongly negative word (`disappointing`)\n",
        "- A neutral word (`bazillion`)\n",
        "- A padding token (`<PAD>`)\n",
        "\n",
        "plus the positional encoding for all positions.\n",
        "\n",
        "Each word will be passed through the model along with positional encodings.\n",
        "\n",
        "We'll then extract and chart the raw attention **energies** that the network computes **before softmax** — showing how much each word is prioritized in the weighted average.\n"
      ],
      "metadata": {
        "id": "rtoGDOMtDeoX"
      },
      "id": "rtoGDOMtDeoX"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Words to test\n",
        "probe_words = [\"phenomenal\", \"disappointing\", \"bazillion\", \"<PAD>\"]\n",
        "\n",
        "# Evaluate in no-grad mode\n",
        "net_att_pe.eval()\n",
        "with torch.no_grad():\n",
        "    for word in probe_words:\n",
        "        token_idx = vocab.get(word, vocab[\"<UNK>\"])\n",
        "        token_embed = net_att_pe.embedding(torch.tensor([token_idx])) # size: 1, features\n",
        "\n",
        "        energies = []\n",
        "        for pos in range(MAX_LEN):\n",
        "            pos_enc = S[pos].unsqueeze(0)                             # size: (1, embed_cnt)\n",
        "            full_input = token_embed + pos_enc                        # size: (1, embed_cnt)\n",
        "            energy = net_att_pe.attention.energy(full_input)          # size: (1, 1)\n",
        "            energies.append(energy.item())\n",
        "\n",
        "        # Plot the energy across positions\n",
        "        plt.figure(figsize=(8, 3))\n",
        "        plt.plot(range(MAX_LEN), energies)\n",
        "        plt.title(f\"Attention Energy vs. Position — {word}\")\n",
        "        plt.xlabel(\"Position (pos_enc index)\")\n",
        "        plt.ylabel(\"Raw Attention Energy\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "_Y9X9VyMD5ZT"
      },
      "id": "_Y9X9VyMD5ZT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a15c60f7ea014664a40b76972082cb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6e0cd517cd7492cadcde80a07f0ee66",
              "IPY_MODEL_f2fc7eed7e8a4eee88030250a1a19eaa",
              "IPY_MODEL_35aea88cc1fa4511b21a18f0c1e32a7f"
            ],
            "layout": "IPY_MODEL_0e7a1ac2525744b1aee7a84cfdc27a3e"
          }
        },
        "b6e0cd517cd7492cadcde80a07f0ee66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafe28f80743488ab1ef7e7d91852ef4",
            "placeholder": "​",
            "style": "IPY_MODEL_83a3c6280f224d21b1b95c429a6c8ca3",
            "value": "README.md: 100%"
          }
        },
        "f2fc7eed7e8a4eee88030250a1a19eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_592710f5443e4b22a7e4912fb838bf3c",
            "max": 8933,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fb548aee07b4ec9a8369b24f87df7c5",
            "value": 8933
          }
        },
        "35aea88cc1fa4511b21a18f0c1e32a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629e125325c647b48fd378916fd7b8af",
            "placeholder": "​",
            "style": "IPY_MODEL_79746c6fdfb04aed9fe0f118efef096d",
            "value": " 8.93k/8.93k [00:00&lt;00:00, 307kB/s]"
          }
        },
        "0e7a1ac2525744b1aee7a84cfdc27a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafe28f80743488ab1ef7e7d91852ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a3c6280f224d21b1b95c429a6c8ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "592710f5443e4b22a7e4912fb838bf3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb548aee07b4ec9a8369b24f87df7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "629e125325c647b48fd378916fd7b8af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79746c6fdfb04aed9fe0f118efef096d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64e50e2bddd24b81aab8963b89884d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eaf29b36be24ab180faf67aa4bf8048",
              "IPY_MODEL_af9af3ae6caf4cf5981e6660059c6fed",
              "IPY_MODEL_7c9f9edd95a94ab29529c22e9630cecb"
            ],
            "layout": "IPY_MODEL_a0780befeec84ac7a88e37c4cb7dd46f"
          }
        },
        "4eaf29b36be24ab180faf67aa4bf8048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8f328c1a264963b7c906b0cc3042f7",
            "placeholder": "​",
            "style": "IPY_MODEL_ff9c3aa47a6e492d9d22dafe3759bfbe",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "af9af3ae6caf4cf5981e6660059c6fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4616d37172a47ae841dbb3440522638",
            "max": 256101803,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a5e6e6f6c5e4999a7d04e2506046998",
            "value": 256101803
          }
        },
        "7c9f9edd95a94ab29529c22e9630cecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b43ec689db741a496f6e8c86abcd9f9",
            "placeholder": "​",
            "style": "IPY_MODEL_35903715bd524a40b4951a449bd44787",
            "value": " 256M/256M [00:00&lt;00:00, 310MB/s]"
          }
        },
        "a0780befeec84ac7a88e37c4cb7dd46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8f328c1a264963b7c906b0cc3042f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9c3aa47a6e492d9d22dafe3759bfbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4616d37172a47ae841dbb3440522638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5e6e6f6c5e4999a7d04e2506046998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b43ec689db741a496f6e8c86abcd9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35903715bd524a40b4951a449bd44787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b7b0111d1c645899f0d38c030006a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d3d7d448e0649bcbfca4b2cbcbd4302",
              "IPY_MODEL_f471763cb2e3427292545ac06aaf9dec",
              "IPY_MODEL_fe66cf067afd4e3db04bff14620f318a"
            ],
            "layout": "IPY_MODEL_44111adfa2d04377b50b05a517b47621"
          }
        },
        "3d3d7d448e0649bcbfca4b2cbcbd4302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4afff3bd3214443a0b8fcc195252eae",
            "placeholder": "​",
            "style": "IPY_MODEL_f7946c9975eb4ae29b4933b11fd57d78",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "f471763cb2e3427292545ac06aaf9dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7cfd50e724b4ae6baaa3ae296af455e",
            "max": 17701458,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7232d41e00414721bc8b688a34e5c2fc",
            "value": 17701458
          }
        },
        "fe66cf067afd4e3db04bff14620f318a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88407057360040acb8c88471425029d8",
            "placeholder": "​",
            "style": "IPY_MODEL_ba3e13590be744969dd38455293bf13d",
            "value": " 17.7M/17.7M [00:00&lt;00:00, 257MB/s]"
          }
        },
        "44111adfa2d04377b50b05a517b47621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4afff3bd3214443a0b8fcc195252eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7946c9975eb4ae29b4933b11fd57d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7cfd50e724b4ae6baaa3ae296af455e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7232d41e00414721bc8b688a34e5c2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88407057360040acb8c88471425029d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3e13590be744969dd38455293bf13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b5813d50db140eca5933ceecd709769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f14edbf698144e41a1bd52597b25915e",
              "IPY_MODEL_bc38233ca0dd4273a6366330f9ea5f83",
              "IPY_MODEL_8ad4efa708634361acd08780507bb091"
            ],
            "layout": "IPY_MODEL_fe564f6f79054c41b7690e87e82e4c91"
          }
        },
        "f14edbf698144e41a1bd52597b25915e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29e38eadd12643c79ab8a37fa1958f79",
            "placeholder": "​",
            "style": "IPY_MODEL_f0606ea899b245abba2db2ba39d342de",
            "value": "Generating train split: 100%"
          }
        },
        "bc38233ca0dd4273a6366330f9ea5f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4adc9a1f105340cfa018f50fe4a3ecfe",
            "max": 560000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a9c4e44dca14a6696e9582f885106fd",
            "value": 560000
          }
        },
        "8ad4efa708634361acd08780507bb091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a5fdfc578ae463098d85ded4b887359",
            "placeholder": "​",
            "style": "IPY_MODEL_e304f062a6744ff3952d9b2384a2d30b",
            "value": " 560000/560000 [00:01&lt;00:00, 303422.56 examples/s]"
          }
        },
        "fe564f6f79054c41b7690e87e82e4c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e38eadd12643c79ab8a37fa1958f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0606ea899b245abba2db2ba39d342de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4adc9a1f105340cfa018f50fe4a3ecfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a9c4e44dca14a6696e9582f885106fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a5fdfc578ae463098d85ded4b887359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e304f062a6744ff3952d9b2384a2d30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7aabeb3193541b69f2aa5bd583ee184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cba04d750694bd2997d35a0d7761c06",
              "IPY_MODEL_e5534950790c4453bdeda05411b16c47",
              "IPY_MODEL_651422a7d7ef4ca2a0cb74bc6e31627f"
            ],
            "layout": "IPY_MODEL_36cb95eb588d45fda56cc68c1c8ef73d"
          }
        },
        "7cba04d750694bd2997d35a0d7761c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_376ced9cfcb444fab373baef65a8ba8f",
            "placeholder": "​",
            "style": "IPY_MODEL_08f482e274fb4adaba85e8add0f5551c",
            "value": "Generating test split: 100%"
          }
        },
        "e5534950790c4453bdeda05411b16c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ee76a8d86fc460db1cb3e98912f0c4d",
            "max": 38000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2edad2d1205b41d598df05493571ac86",
            "value": 38000
          }
        },
        "651422a7d7ef4ca2a0cb74bc6e31627f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f4eed357e6e44ac9e0d7b889bfca35f",
            "placeholder": "​",
            "style": "IPY_MODEL_01df3cc8c94f4bd48768b10106ab3ea7",
            "value": " 38000/38000 [00:00&lt;00:00, 248995.53 examples/s]"
          }
        },
        "36cb95eb588d45fda56cc68c1c8ef73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "376ced9cfcb444fab373baef65a8ba8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f482e274fb4adaba85e8add0f5551c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee76a8d86fc460db1cb3e98912f0c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2edad2d1205b41d598df05493571ac86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f4eed357e6e44ac9e0d7b889bfca35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01df3cc8c94f4bd48768b10106ab3ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}